{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tema 2 AI\n",
    "Ilie Andrei-Leonard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializam libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_TYPE = \"simple\" # simple, complex"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functii pentru generarea de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples(dataset_type = \"simple\", n_samples = 500, n_features = 1, noise = 20):\n",
    "    if dataset_type == \"simple\":\n",
    "        X, t = datasets.make_regression(n_samples=n_samples, n_features=n_features, n_informative=1, noise=noise, random_state=37)\n",
    "        # fig = plt.figure(figsize=(4, 4))\n",
    "        # plt.xlabel(\"x (feature)\")\n",
    "        # plt.ylabel(\"y (output)\")\n",
    "        # plt.title(\"Synthetic data set\")\n",
    "        # plt.scatter(X, y)\n",
    "        # plt.show()\n",
    "        return X, t\n",
    "    \n",
    "    elif dataset_type == \"complex\":\n",
    "        n_samples = 300\n",
    "        x = np.linspace(-10, 10, n_samples) # coordinates\n",
    "        noise_sample = np.random.normal(0,0.5,n_samples)\n",
    "        sine_wave = x + np.sin(4*x) + noise_sample\n",
    "        plt.plot(x, sine_wave, 'o')\n",
    "        plt.show()\n",
    "        return x, sine_wave\n",
    "    else:\n",
    "        raise ValueError(\"Unknown dataset type: \" + dataset_type)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasa pentru LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(object):\n",
    "    \"\"\"\n",
    "    Modelul de Regresie Liniara\n",
    "    y = X @ w \n",
    "        - valoarea prezisÄƒ de model\n",
    "    t ~ N(t|X @ w, var) \n",
    "        - valorile de antrenare (target) sunt fac parte dintr-o distributie normala in jurul mean-ului X@w, \n",
    "          la care se adauga zgomot dat de varianta `var`\n",
    "    \"\"\"\n",
    "\n",
    "    def fit(self, X, t):\n",
    "        \"\"\"\n",
    "        Antrenarea modelului in sensul celor mai mici patrate (least squares fitting)\n",
    "        Parameterii\n",
    "        ----------\n",
    "        X : (N, D) np.ndarray\n",
    "            variabilele de intrare\n",
    "        t : (N,) np.ndarray\n",
    "            variabilele tinta (target / ground truth)\n",
    "        \"\"\"\n",
    "        # TODO codul vostru aici: calculati vectorul de ponderi w\n",
    "        # print(X.shape)\n",
    "        N, D = X.shape\n",
    "        \n",
    "        # ar trebui facut cu np.dot sau cu @\n",
    "        self.w = np.linalg.pinv(X) @ t\n",
    "        # print(self.w)\n",
    "        # end \n",
    "        \n",
    "        self.var = np.mean(np.square(X @ self.w - t))\n",
    "\n",
    "    def predict(self, X, return_std=False):\n",
    "        \"\"\"\n",
    "        Intoarce valoari prezise de model pentru sample-uri X\n",
    "        Parametrii\n",
    "        ----------\n",
    "        X : (N, D) np.ndarray\n",
    "            sample-uri de valori D-dimensionale pentru care se doreste predictia valorii conform modelului\n",
    "        return_std : bool, optional\n",
    "            intoarce deviatia standard a fiecarei valori prezice, daca e setat pe True\n",
    "        \n",
    "        Intoarce\n",
    "        -------\n",
    "        y : (N,) np.ndarray\n",
    "            vector de valori prezise\n",
    "        y_std : (N,) np.ndarray\n",
    "            deviatia standard a fiecarei valori prezise\n",
    "        \"\"\"\n",
    "        # TODO codul vostru aici: calculati valoarea prezisa de modelul vostru\n",
    "        N, D = X.shape\n",
    "        y = np.zeros(N)\n",
    "\n",
    "        y = X @ self.w\n",
    "        # end codul vostru aici\n",
    "        \n",
    "        if return_std:\n",
    "            # TODO codul vostru aici: intoarceti un vector de aceeasi dimensiune cu y, care \n",
    "            # are in fiecare pozitie o valoare egala cu deviatia standard a modelului antrenat (i.e. sqrt(var))\n",
    "            y_std = np.ones_like(y) * math.sqrt(self.var)\n",
    "\n",
    "            # aplic sqrt(var) pe toti y\n",
    "            return y, y_std\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_polynomial_features(X, M):\n",
    "    phi = X\n",
    "    # TODO codul vostru aici: intoarceti valorile phi_n astfel incat pentru fiecare \n",
    "    # intrare x phi_n = [1, x, x^2, ..., x^M]\n",
    "    phi_n = np.zeros((X.size, M+1))\n",
    "\n",
    "    for i in range(X.size):\n",
    "        current = np.zeros(M+1)\n",
    "\n",
    "        for j in range(M+1):\n",
    "            current[j] = X[i][0] ** j\n",
    "\n",
    "        phi_n[i] = current\n",
    "        # print(X[i][0], i)\n",
    "\n",
    "    phi = phi_n\n",
    "\n",
    "\n",
    "    # end\n",
    "    \n",
    "    # nota: phi trebuie sa fie la final un np.array de dimensiune (N, M+1), unde N este numarul de linii din X\n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functia de eroare conform PDF\n",
    "def mean_squared_error(y, t):\n",
    "    return np.mean((y - t) * (y- t))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Solutia in forma inchisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generam datele de test si train\n",
    "# Folosind proportia 20/80 \n",
    "X, t = generate_examples(dataset_type=DATASET_TYPE)\n",
    "X_train, X_test, t_train, t_test = train_test_split(X, t, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_train, t_train, s=50, label=\"Train examples\")\n",
    "plt.scatter(X_test, t_test, s=50, label=\"Test examples\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper right', ncol=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creati un model liniar\n",
    "# model = ...\n",
    "model = LinearRegression()\n",
    "\n",
    "# Folositi functia extract_polynomial_features pentru a introduce termenul de bias in matricile X_train si X_test\n",
    "X_train_feat = extract_polynomial_features(X_train, 1)\n",
    "X_test_feat = extract_polynomial_features(X_test, 1)\n",
    "\n",
    "# antrenati modelul vostru\n",
    "model.fit(X_train_feat, t_train)\n",
    "\n",
    "# obtineti predictia pe setul de antrenare si pe setul de test\n",
    "y_train = model.predict(X_train_feat) \n",
    "y_train = np.zeros(X_train.size)\n",
    "y_test = np.zeros(X_test.size)\n",
    "y_test_std = np.zeros(X_test.size)\n",
    "y_test, y_test_std = model.predict(X_test_feat, True)\n",
    "\n",
    "# Sortam\n",
    "sorted_stuffs = list(zip(*sorted(zip(X_test,y_test))))\n",
    "X_test_sorted = sorted_stuffs[0]\n",
    "y_test_sorted = sorted_stuffs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train error:\", mean_squared_error(y_train, t_train))\n",
    "print(\"Test  error:\", mean_squared_error(y_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(X_train, t_train, facecolor=\"none\", color=\"b\", s=50, label=\"training data\")\n",
    "plt.scatter(X_test, t_test, facecolor=\"none\", color=\"r\", s=50, label=\"test data\")\n",
    "plt.plot(X_test_sorted, y_test_sorted, label=\"prediction\")\n",
    "plt.fill_between(\n",
    "    np.squeeze(X_test_sorted), y_test_sorted - y_test_std, y_test_sorted + y_test_std,\n",
    "    color=\"orange\", alpha=0.5, label=\"std.\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, t, epochs, eta):\n",
    "    w = np.zeros(X.shape[1]) # initialize weights to zero\n",
    "    risks = [] # store risks for each epoch\n",
    "    function_values = [] # store function values for each epoch\n",
    "    for epoch in range(epochs):\n",
    "        y = np.dot(X, w) # calculate output\n",
    "        error = y - t # calculate error\n",
    "        gradient = np.dot(X.T, error) / len(X) # calculate gradient\n",
    "        w -= eta * gradient # update weights\n",
    "\n",
    "        risk = np.mean(error ** 2) / 2 # calculate risk\n",
    "        risks.append(risk)\n",
    "        \n",
    "        function_value = np.mean((y - t) ** 2) / 2 # calculate function value\n",
    "        function_values.append(function_value)\n",
    "    return w, risks, function_values\n",
    "\n",
    "epochs = 50\n",
    "eta = 0.05 \n",
    "w, risks, function_values = gradient_descent(X_train, t_train, epochs, eta)\n",
    "plt.plot(range(1, epochs+1), risks, label='Optimal loss')\n",
    "plt.scatter(range(1, epochs+1), function_values, label='function value')\n",
    "plt.xlabel('number of iterations')\n",
    "plt.ylabel('Empirical Risk')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "# plt.scatter(X_train, t_train, facecolor=\"none\", color=\"b\", s=50, label=\"training data\")\n",
    "plt.scatter(X_test, t_test, facecolor=\"none\", color=\"r\", s=50, label=\"test data\")\n",
    "plt.plot(X_test_sorted, y_test_sorted, label=\"Closed-form Solution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
